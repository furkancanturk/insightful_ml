{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-LEARNING FOR THE MAZE GAME\n",
    "    Author: Furkan Cant√ºrk\n",
    "    Date: 01.09.2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(current_state, p):\n",
    "    global current_pos, epsilon\n",
    "    possible_actions = []\n",
    "    if np.random.uniform() <= epsilon:\n",
    "        if current_pos[0] != 0: possible_actions.append(0)\n",
    "        if current_pos[0] != n-1: possible_actions.append(1)\n",
    "        if current_pos[1] != 0: possible_actions.append(2)\n",
    "        if current_pos[1] != n-1: possible_actions.append(3)\n",
    "        \n",
    "        intended_action = possible_actions[randint(0, len(possible_actions) - 1)]\n",
    "        \n",
    "        if np.random.uniform() > p: # p is given as 0 for deterministic case, otherwise 0.5\n",
    "            return intended_action\n",
    "        else:\n",
    "            possible_actions.remove(intended_action)\n",
    "            return possible_actions[randint(0, len(possible_actions) - 1)]\n",
    "\n",
    "    else:\n",
    "        if current_pos[0] != 0: possible_actions.append(Q[current_state,0])\n",
    "        else: possible_actions.append(-999)\n",
    "            \n",
    "        if current_pos[0] != n-1: possible_actions.append(Q[current_state,1])\n",
    "        else: possible_actions.append(-999)\n",
    "            \n",
    "        if current_pos[1] != 0: possible_actions.append(Q[current_state,2])\n",
    "        else: possible_actions.append(-999)\n",
    "            \n",
    "        if current_pos[1] != n-1: possible_actions.append(Q[current_state,3])\n",
    "        else: possible_actions.append(-999)\n",
    "        # choose action randomly if there are multiple max Q values  \n",
    "        intended_action = random.choice([i for i, a in enumerate(possible_actions) if a == max(possible_actions)])\n",
    "        \n",
    "        if np.random.uniform() > p: # p is given as 0 for deterministic case, otherwise 0.5\n",
    "            return intended_action\n",
    "        else:\n",
    "            possible_actions = [i for i, a in enumerate(possible_actions) if a != -999]\n",
    "            possible_actions.remove(intended_action)\n",
    "            return random.choice(possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def off_policy_episode(): # probability of not intended actions is 0 \n",
    "    global current_pos, epsilon\n",
    "    current_pos = [n-1,0] # start\n",
    "    current_state = states[(current_pos[0], current_pos[1])]\n",
    "    \n",
    "    while current_state != terminal_state:\n",
    "        action = select_action(current_state, 0) # deterministic\n",
    "        #take the  action\n",
    "        if action == 0: current_pos[0] -= 1\n",
    "        elif action == 1: current_pos[0] += 1\n",
    "        elif action == 2: current_pos[1] -= 1\n",
    "        elif action == 3: current_pos[1] += 1\n",
    "        \n",
    "        r = reward[current_pos[0],current_pos[1]]\n",
    "        new_state = states[(current_pos[0], current_pos[1])]\n",
    "        \n",
    "        Q[current_state, action] += l_rate*( r + gamma * np.max(Q[new_state]) - Q[current_state,action])\n",
    "        current_state = new_state\n",
    "        epsilon -= 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_policy_episode(): # probability of intended action is 0.5 \n",
    "    global current_pos, epsilon\n",
    "    current_pos = [n-1,0] # start\n",
    "    current_state = states[(current_pos[0], current_pos[1])]\n",
    "    action = select_action(current_state, 0.5) # undeterministic\n",
    "    \n",
    "    while current_state != terminal_state:\n",
    "        #take the action\n",
    "        if action == 0: current_pos[0] -= 1\n",
    "        elif action == 1: current_pos[0] += 1\n",
    "        elif action == 2: current_pos[1] -= 1\n",
    "        elif action == 3: current_pos[1] += 1\n",
    "        r = reward[current_pos[0],current_pos[1]]\n",
    "        new_state = states[(current_pos[0], current_pos[1])]\n",
    "        new_action = select_action(new_state, 0.5) # undeterministic\n",
    "        \n",
    "        Q[current_state, action] += l_rate*( r + gamma * Q[new_state, new_action] - Q[current_state,action])\n",
    "        \n",
    "        current_state = new_state\n",
    "        action = new_action\n",
    "        epsilon -= 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_state(state):\n",
    "    act = np.argmax(Q[state])\n",
    "    if act == 0: return state - 8\n",
    "    elif act == 1: return state + 8\n",
    "    elif act == 2: return state - 1\n",
    "    elif act == 3: return state + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path():\n",
    "    path = []\n",
    "    next_s = states[(start[0],start[1])]\n",
    "    while next_s != states[(terminal[0], terminal[1])]:\n",
    "        path.append(next_s)\n",
    "        next_s = get_next_state(next_s)\n",
    "    path.append(next_s)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "tx = 6\n",
    "ty = 2\n",
    "terminal = [ty,tx]\n",
    "start = [n-1,0]\n",
    "maze = np.zeros([n,n])\n",
    "\n",
    "l_rate = 0.1\n",
    "gamma = 0.9\n",
    "\n",
    "directions = {\"up\": 0, \"down\" : 1, \"left\" : 2, \"right\" : 3}\n",
    "states = {}\n",
    "k = 0\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        states[(i,j)] = k\n",
    "        maze[i,j] = k\n",
    "        k+=1\n",
    "terminal_state = states[(terminal[0], terminal[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OFF-POLICY - DETERMINISTIC ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "reward = np.zeros((n,n))\n",
    "reward[ty,tx] = 100\n",
    "Q = np.zeros((n**2,4))\n",
    "epsilon = 0.7\n",
    "for i in range(1000):\n",
    "    off_policy_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States through the off-policy path:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, 18., 19., 20., 21., 22., nan],\n",
       "       [nan, nan, 26., nan, nan, nan, nan, nan],\n",
       "       [nan, nan, 34., nan, nan, nan, nan, nan],\n",
       "       [40., 41., 42., nan, nan, nan, nan, nan],\n",
       "       [48., nan, nan, nan, nan, nan, nan, nan],\n",
       "       [56., nan, nan, nan, nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = path()\n",
    "result_maze = maze.copy()\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if maze[i, j] not in p:\n",
    "            result_maze[i,j] = None\n",
    "print(\"States through the off-policy path:\")            \n",
    "result_maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acts = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if(sum(Q[states[(i,j)]]!=0)):\n",
    "            best_acts[i,j] = np.argmax(Q[states[(i,j)]])\n",
    "        else:\n",
    "            best_acts[i,j]= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan,  1., nan, nan, nan, nan, nan],\n",
       "       [nan, nan,  1., nan, nan, nan, nan, nan],\n",
       "       [nan, nan,  3.,  3.,  3.,  3., nan,  2.],\n",
       "       [nan, nan,  0.,  0., nan,  0.,  0.,  2.],\n",
       "       [nan, nan,  0., nan,  3.,  3.,  0., nan],\n",
       "       [ 3.,  3.,  0., nan,  0., nan, nan, nan],\n",
       "       [ 0.,  0.,  0.,  3.,  0.,  2., nan, nan],\n",
       "       [ 0., nan, nan,  0., nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acts  # directions = {\"up\": 0, \"down\" : 1, \"left\" : 2, \"right\" : 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,  73.],\n",
       "       [  0.,   0.,   0.,  81.],\n",
       "       [  0.,   0.,   0.,  90.],\n",
       "       [  0.,   0.,   0., 100.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,  10.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [ 66.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  4.,   0.,   0.,   0.],\n",
       "       [ 65.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   1.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [ 59.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   1.],\n",
       "       [  0.,   0.,   0.,   5.],\n",
       "       [ 23.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,  43.],\n",
       "       [  0.,   0.,   0.,  48.],\n",
       "       [ 53.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [ 39.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [ 35.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(Q) # off-policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ON-POLICY - UNDETERMINISTIC ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "reward = np.zeros((n,n))\n",
    "reward[ty,tx] = 100\n",
    "Q = np.zeros((n**2,4))\n",
    "epsilon = 0.7\n",
    "for i in range(1000):\n",
    "    on_policy_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States through the on-policy path:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, 21., 22., nan],\n",
       "       [nan, nan, nan, nan, nan, 29., nan, nan],\n",
       "       [nan, nan, nan, 35., 36., 37., nan, nan],\n",
       "       [nan, nan, 42., 43., nan, nan, nan, nan],\n",
       "       [48., 49., 50., nan, nan, nan, nan, nan],\n",
       "       [56., nan, nan, nan, nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = path()\n",
    "result_maze = maze.copy()\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if maze[i, j] not in p:\n",
    "            result_maze[i,j] = None\n",
    "print(\"States through the on-policy path:\")            \n",
    "result_maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acts = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if(sum(Q[states[(i,j)]]!=0)):\n",
    "            best_acts[i,j] = np.argmax(Q[states[(i,j)]])\n",
    "        else:\n",
    "            best_acts[i,j]= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  3.,  3.,  3.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  3.,  3.,  3.,  3.,  3., nan,  2.],\n",
       "       [ 3.,  3.,  3.,  3.,  3.,  0.,  0.,  0.],\n",
       "       [ 3.,  3.,  3.,  3.,  3.,  0.,  0.,  0.],\n",
       "       [ 3.,  3.,  3.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 3.,  3.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  3.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acts  # directions = {\"up\": 0, \"down\" : 1, \"left\" : 2, \"right\" : 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [  0.,   3.,   0.,   5.],\n",
       "       [  0.,  12.,   1.,  16.],\n",
       "       [  0.,  29.,   8.,  11.],\n",
       "       [  0.,  39.,   8.,   8.],\n",
       "       [  0.,  46.,   4.,   7.],\n",
       "       [  0.,  22.,  11.,   0.],\n",
       "       [  0.,   1.,   0.,   1.],\n",
       "       [  0.,   6.,   0.,   2.],\n",
       "       [  1.,  15.,   2.,  11.],\n",
       "       [  8.,  27.,   5.,  25.],\n",
       "       [ 11.,  43.,  13.,  39.],\n",
       "       [ 21.,  69.,  31.,  39.],\n",
       "       [  7., 100.,  28.,  26.],\n",
       "       [  6.,  57.,  44.,   0.],\n",
       "       [  0.,   4.,   0.,   3.],\n",
       "       [  2.,   7.,   1.,  16.],\n",
       "       [  4.,  18.,   5.,  32.],\n",
       "       [ 13.,  31.,  20.,  46.],\n",
       "       [ 27.,  39.,  31.,  72.],\n",
       "       [ 48.,  49.,  48., 100.],\n",
       "       [  0.,   0.,   0.,   0.],\n",
       "       [ 35.,  40., 100.,   0.],\n",
       "       [  1.,   5.,   0.,  12.],\n",
       "       [  5.,   9.,   4.,  15.],\n",
       "       [ 18.,  15.,   9.,  27.],\n",
       "       [ 23.,  22.,  17.,  39.],\n",
       "       [ 43.,  29.,  28.,  58.],\n",
       "       [ 77.,  39.,  38.,  67.],\n",
       "       [100.,  38.,  47.,  48.],\n",
       "       [ 57.,  32.,  55.,   0.],\n",
       "       [  7.,   6.,   0.,  10.],\n",
       "       [  6.,   7.,   6.,  15.],\n",
       "       [ 18.,  11.,   9.,  22.],\n",
       "       [ 29.,  15.,  15.,  29.],\n",
       "       [ 36.,  22.,  18.,  39.],\n",
       "       [ 53.,  26.,  30.,  42.],\n",
       "       [ 72.,  24.,  38.,  33.],\n",
       "       [ 46.,  22.,  44.,   0.],\n",
       "       [  6.,   5.,   0.,   8.],\n",
       "       [ 10.,   7.,   6.,  12.],\n",
       "       [ 14.,   9.,   8.,  16.],\n",
       "       [ 23.,  11.,  11.,  20.],\n",
       "       [ 25.,  14.,  18.,  23.],\n",
       "       [ 36.,  13.,  17.,  24.],\n",
       "       [ 48.,  13.,  21.,  16.],\n",
       "       [ 36.,   7.,  22.,   0.],\n",
       "       [  6.,   5.,   0.,   7.],\n",
       "       [  7.,   6.,   5.,   9.],\n",
       "       [ 12.,   7.,   7.,  11.],\n",
       "       [ 16.,   7.,   9.,  12.],\n",
       "       [ 21.,   6.,  10.,  14.],\n",
       "       [ 26.,   4.,  10.,   9.],\n",
       "       [ 27.,   3.,   6.,   7.],\n",
       "       [ 16.,   0.,   8.,   0.],\n",
       "       [  6.,   0.,   0.,   6.],\n",
       "       [  7.,   0.,   5.,   7.],\n",
       "       [  9.,   0.,   5.,   8.],\n",
       "       [ 11.,   0.,   7.,   8.],\n",
       "       [ 12.,   0.,   5.,   5.],\n",
       "       [ 14.,   0.,   4.,   2.],\n",
       "       [  9.,   0.,   2.,   1.],\n",
       "       [  6.,   0.,   1.,   0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(Q) # on-policy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
